{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, \\\n",
    "  Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "  from keras.layers import CuDNNLSTM as LSTM\n",
    "  from keras.layers import CuDNNGRU as GRU\n",
    "\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we do softmax over the time axis\n",
    "# expected shape is N x T x D\n",
    "# note: the latest version of Keras allows you to pass in axis arg\n",
    "def softmax_over_time(x):\n",
    "  assert(K.ndim(x) > 2)\n",
    "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "  s = K.sum(e, axis=1, keepdims=True)\n",
    "  return e / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 256\n",
    "LATENT_DIM_DECODER = 256 # idea: make it different to ensure things all fit together properly!\n",
    "NUM_SAMPLES = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 10000\n"
     ]
    }
   ],
   "source": [
    "input_texts = []\n",
    "target_texts = [] \n",
    "target_texts_inputs = [] \n",
    "\n",
    "t = 0\n",
    "for line in open('../../machine_learning_examples/large_files/translation/cmn.txt', encoding='utf-8'):\n",
    "  t += 1\n",
    "  if t > NUM_SAMPLES:\n",
    "    break\n",
    "\n",
    "  if '\\t' not in line:\n",
    "    continue\n",
    "\n",
    "  input_text, translation, _ = line.rstrip().split('\\t')\n",
    "\n",
    "  target_text = translation \n",
    "  target_text_input = translation\n",
    "\n",
    "  input_texts.append(input_text)\n",
    "  target_texts.append(target_text)\n",
    "  target_texts_inputs.append(target_text_input)\n",
    "print(\"num samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3472 unique input tokens.\n"
     ]
    }
   ],
   "source": [
    "# tokenize the inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "# get the word to index mapping for input language\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_input = max(len(s) for s in input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for chinese, using jieba to tokenize => establish word2idx => establish target sequences\n",
    "\n",
    "stop_words = []\n",
    "with open('../../machine_learning_examples/corpus/stop_words.txt') as f:\n",
    "    for line in f:\n",
    "        stop_words.append(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seg = []\n",
    "target_input_seg = []\n",
    "for t in target_texts:\n",
    "    seg = jieba.lcut(t)\n",
    "    seg = [s for s in seg if s not in stop_words]\n",
    "    target_seg.append(seg + ['<eos>'])\n",
    "    target_input_seg.append(['<sos>'] + seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_outputs = {}\n",
    "\n",
    "for L in target_seg:\n",
    "    for token in L + ['<sos>']:\n",
    "        if token not in word2idx_outputs:\n",
    "            word2idx_outputs[token] = len(word2idx_outputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sequences = []\n",
    "target_input_sequences = []\n",
    "\n",
    "for L in target_seg:\n",
    "    sequence = []\n",
    "    for seg in L:\n",
    "        sequence.append(word2idx_outputs.get(seg))\n",
    "    target_sequences.append(sequence)\n",
    "\n",
    "for L in target_input_seg:\n",
    "    sequence = []\n",
    "    for seg in L:\n",
    "        sequence.append(word2idx_outputs.get(seg))\n",
    "    target_input_sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6651 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "max_len_target = max(len(s) for s in target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs.shape: (10000, 9)\n",
      "encoder_inputs[0]: [  0   0   0   0   0   0   0   0 911]\n",
      "decoder_inputs[0]: [3 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "decoder_inputs.shape: (10000, 13)\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(target_input_sequences, maxlen=max_len_target, padding='post')\n",
    "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# store all the pre-trained word vectors\n",
    "word2vec = {}\n",
    "with open(os.path.join('../../machine_learning_examples/large_files/glove.6B/glove.6B.%sd.txt' % EMBEDDING_DIM), encoding='utf-8') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "    \n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "  if i < MAX_NUM_WORDS:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=max_len_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, since we cannot use sparse\n",
    "# categorical cross entropy when we have sequences\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(input_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")\n",
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decoder_targets):\n",
    "  for t, word in enumerate(d):\n",
    "    decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### build the model #####\n",
    "\n",
    "# Set up the encoder\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = Bidirectional(LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_sequences=True,\n",
    "  # dropout=0.5 \n",
    "))\n",
    "encoder_outputs = encoder(x)\n",
    "\n",
    "\n",
    "# Set up the decoder \n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "# this word embedding will not use pre-trained vectors\n",
    "# although you could\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Attention #########\n",
    "# Attention layers need to be global because they will be repeated Ty times at the decoder\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(h, st_1):\n",
    "  # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "  # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
    " \n",
    "  # copy s(t-1) Tx times\n",
    "  # now shape = (Tx, LATENT_DIM_DECODER)\n",
    "  st_1 = attn_repeat_layer(st_1)\n",
    "\n",
    "  # Concatenate all h(t)'s with s(t-1)\n",
    "  # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "  x = attn_concat_layer([h, st_1])\n",
    "\n",
    "  # Neural net first layer\n",
    "  x = attn_dense1(x)\n",
    "\n",
    "  # Neural net second layer with special softmax over time\n",
    "  alphas = attn_dense2(x)\n",
    "\n",
    "  # \"Dot\" the alphas and the h's\n",
    "  # Remember a.dot(b) = sum over a[t] * b[t]\n",
    "  context = attn_dot([alphas, h])\n",
    "\n",
    "  return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the rest of the decoder (after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "\n",
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead we need to do Ty steps # And in each of those steps, we need to consider all Tx h's  \n",
    "# s, c will be re-assigned in each iteration of the loop\n",
    "s = initial_s\n",
    "c = initial_c\n",
    "\n",
    "# collect outputs in a list at first\n",
    "outputs = []\n",
    "for t in range(max_len_target): # Ty times\n",
    "  # get the context using attention\n",
    "  context = one_step_attention(encoder_outputs, s)\n",
    "\n",
    "  # we need a different layer for each time step\n",
    "  selector = Lambda(lambda x: x[:, t:t+1])\n",
    "  xt = selector(decoder_inputs_x)\n",
    "  \n",
    "  # combine \n",
    "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "\n",
    "  # pass the combined [context, last word] into the LSTM\n",
    "  # along with [s, c]\n",
    "  # get the new [s, c] and output\n",
    "  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "\n",
    "  # final dense layer to get next word prediction\n",
    "  decoder_outputs = decoder_dense(o)\n",
    "  outputs.append(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'outputs' is now a list of length Ty\n",
    "# each element is of shape (batch size, output vocab size)\n",
    "# therefore if we simply stack all the outputs into 1 tensor\n",
    "# it would be of shape T x N x D\n",
    "# we would like it to be of shape N x T x D\n",
    "\n",
    "def stack_and_transpose(x):\n",
    "  # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
    "  x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
    "  x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
    "  return x\n",
    "\n",
    "# make it a layer\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)\n",
    "\n",
    "# create the model\n",
    "model = Model(\n",
    "  inputs=[\n",
    "    encoder_inputs_placeholder,\n",
    "    decoder_inputs_placeholder,\n",
    "    initial_s, \n",
    "    initial_c,\n",
    "  ],\n",
    "  outputs=outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  mask = K.cast(y_true > 0, dtype='float32')\n",
    "  out = mask * y_true * K.log(y_pred)\n",
    "  return -K.sum(out) / K.sum(mask)\n",
    "\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  targ = K.argmax(y_true, axis=-1)\n",
    "  pred = K.argmax(y_pred, axis=-1)\n",
    "  correct = K.cast(K.equal(targ, pred), dtype='float32')\n",
    "\n",
    "  # 0 is padding, don't include those\n",
    "  mask = K.cast(K.greater(targ, 0), dtype='float32')\n",
    "  n_correct = K.sum(mask * correct)\n",
    "  n_total = K.sum(mask)\n",
    "  return n_correct / n_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Amo.CH.Liu\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 3.1529 - acc: 0.0142 - val_loss: 3.2081 - val_acc: 0.0719\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 2.3250 - acc: 0.2060 - val_loss: 3.0837 - val_acc: 0.1969\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 2.2150 - acc: 0.2427 - val_loss: 3.0475 - val_acc: 0.1962\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 2.1531 - acc: 0.2446 - val_loss: 3.0481 - val_acc: 0.1980\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 2.1102 - acc: 0.2475 - val_loss: 3.0301 - val_acc: 0.2021\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 2.0754 - acc: 0.2527 - val_loss: 3.0015 - val_acc: 0.2053\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 2.0302 - acc: 0.2622 - val_loss: 2.9714 - val_acc: 0.2101\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.9815 - acc: 0.2697 - val_loss: 2.9184 - val_acc: 0.2158\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.9290 - acc: 0.2764 - val_loss: 2.8855 - val_acc: 0.2339\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.8753 - acc: 0.2947 - val_loss: 2.8572 - val_acc: 0.2375\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.8194 - acc: 0.3103 - val_loss: 2.8345 - val_acc: 0.2443\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.7620 - acc: 0.3345 - val_loss: 2.8057 - val_acc: 0.2713\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.7041 - acc: 0.3509 - val_loss: 2.7667 - val_acc: 0.2742\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.6463 - acc: 0.3658 - val_loss: 2.7454 - val_acc: 0.2785\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.5906 - acc: 0.3817 - val_loss: 2.7290 - val_acc: 0.2863\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.5336 - acc: 0.3941 - val_loss: 2.7164 - val_acc: 0.2906\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.4796 - acc: 0.4073 - val_loss: 2.7063 - val_acc: 0.3021\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.4273 - acc: 0.4181 - val_loss: 2.6904 - val_acc: 0.3072\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.3763 - acc: 0.4283 - val_loss: 2.6811 - val_acc: 0.3089\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.3244 - acc: 0.4389 - val_loss: 2.6718 - val_acc: 0.3070\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.2739 - acc: 0.4488 - val_loss: 2.6826 - val_acc: 0.3155\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.2238 - acc: 0.4597 - val_loss: 2.6773 - val_acc: 0.3189\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.1729 - acc: 0.4698 - val_loss: 2.6757 - val_acc: 0.3203\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.1250 - acc: 0.4791 - val_loss: 2.6751 - val_acc: 0.3223\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.0761 - acc: 0.4915 - val_loss: 2.6712 - val_acc: 0.3237\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1.0265 - acc: 0.5055 - val_loss: 2.6788 - val_acc: 0.3272\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.9783 - acc: 0.5194 - val_loss: 2.6851 - val_acc: 0.3247\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.9292 - acc: 0.5355 - val_loss: 2.6841 - val_acc: 0.3321\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.8831 - acc: 0.5488 - val_loss: 2.6837 - val_acc: 0.3219\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.8378 - acc: 0.5664 - val_loss: 2.6853 - val_acc: 0.3334\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss=custom_loss, metrics=[acc])\n",
    "\n",
    "# train the model\n",
    "z = np.zeros((len(encoder_inputs), LATENT_DIM_DECODER)) # initial [s, c]\n",
    "\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.2,\n",
    "  callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('attention.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='acc')\n",
    "plt.plot(r.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Make predictions #####\n",
    "# As with the poetry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "# i.e. h(1), ..., h(Tx)\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
    "\n",
    "# next we define a T=1 decoder model\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# no need to loop over attention steps this time because there is only one step\n",
    "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
    "\n",
    "# combine context with last word\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# lstm and final dense\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: we don't really need the final stack and tranpose\n",
    "# because there's only 1 output\n",
    "# it is already of size N x D\n",
    "# no need to make it 1 x N x D --> N x 1 x D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "decoder_model = Model(\n",
    "  inputs=[\n",
    "    decoder_inputs_single,\n",
    "    encoder_outputs_as_input,\n",
    "    initial_s, \n",
    "    initial_c\n",
    "  ],\n",
    "  outputs=[decoder_outputs, s, c]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  enc_out = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "  \n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "\n",
    "\n",
    "  # [s, c] will be updated in each loop iteration\n",
    "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "\n",
    "\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  for _ in range(max_len_target):\n",
    "    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
    "        \n",
    "\n",
    "    # Get next word\n",
    "    idx = np.argmax(o.flatten())\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "  return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: The war has not ended.\n",
      "Predicted translation:   \n",
      "Actual translation: \n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: Don't bite on the right side.\n",
      "Predicted translation:    \n",
      "Actual translation: \n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: What time will you leave?\n",
      "Predicted translation:     \n",
      "Actual translation: \n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: Let's just eat.\n",
      "Predicted translation:   \n",
      "Actual translation: \n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: The moon was full last night.\n",
      "Predicted translation:     \n",
      "Actual translation: \n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: I've lost my watch.\n",
      "Predicted translation:      \n",
      "Actual translation: \n",
      "Continue? [Y/n]n\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mident\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\jupyter_client\\session.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[0;32m    802\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m             \u001b[0mmsg_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[1;34m(self, flags, copy, track)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;31m# have first part already, only loop while more to receive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-53d5ca5dd35f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Actual translation:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_texts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m   \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Continue? [Y/n]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mans\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         )\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  # Do some test translations\n",
    "  i = np.random.choice(len(input_texts))\n",
    "  input_seq = encoder_inputs[i:i+1]\n",
    "  translation = decode_sequence(input_seq)\n",
    "  print('-')\n",
    "  print('Input sentence:', input_texts[i])\n",
    "  print('Predicted translation:', translation)\n",
    "  print('Actual translation:', target_texts[i])\n",
    "\n",
    "  ans = input(\"Continue? [Y/n]\")\n",
    "  if ans and ans.lower().startswith('n'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "848"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "53 * 16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
