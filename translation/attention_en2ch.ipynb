{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, \\\n",
    "  Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jieba\n",
    "\n",
    "if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "  from keras.layers import CuDNNLSTM as LSTM\n",
    "  from keras.layers import CuDNNGRU as GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 256\n",
    "LATENT_DIM_DECODER = 256\n",
    "NUM_SAMPLES = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 10000\n"
     ]
    }
   ],
   "source": [
    "input_texts = []\n",
    "target_texts = [] \n",
    "target_texts_inputs = [] \n",
    "\n",
    "t = 0\n",
    "for line in open('../large_files/translation/cmn.txt', encoding='utf-8'):\n",
    "  t += 1\n",
    "  if t > NUM_SAMPLES:\n",
    "    break\n",
    "\n",
    "  if '\\t' not in line:\n",
    "    continue\n",
    "\n",
    "  input_text, translation, _ = line.rstrip().split('\\t')\n",
    "\n",
    "  target_text = translation \n",
    "  target_text_input = translation\n",
    "\n",
    "  input_texts.append(input_text)\n",
    "  target_texts.append(target_text)\n",
    "  target_texts_inputs.append(target_text_input)\n",
    "print(\"num samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3472 unique input tokens.\n"
     ]
    }
   ],
   "source": [
    "# tokenize the inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "# get the word to index mapping for input language\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
    "\n",
    "max_len_input = max(len(s) for s in input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for chinese, using jieba to tokenize => establish word2idx => establish target sequences\n",
    "\n",
    "stop_words = []\n",
    "with open('../corpus/ch_stopwords.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        stop_words.append(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 2.428 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "target_seg = []\n",
    "target_input_seg = []\n",
    "for t in target_texts:\n",
    "    seg = jieba.lcut(t)\n",
    "    seg = [s for s in seg if s not in stop_words]\n",
    "    target_seg.append(seg + ['<eos>'])\n",
    "    target_input_seg.append(['<sos>'] + seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_outputs = {}\n",
    "\n",
    "for L in target_seg:\n",
    "    for token in L + ['<sos>']:\n",
    "        if token not in word2idx_outputs:\n",
    "            word2idx_outputs[token] = len(word2idx_outputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sequences = []\n",
    "target_input_sequences = []\n",
    "\n",
    "for L in target_seg:\n",
    "    sequence = []\n",
    "    for seg in L:\n",
    "        sequence.append(word2idx_outputs.get(seg))\n",
    "    target_sequences.append(sequence)\n",
    "\n",
    "for L in target_input_seg:\n",
    "    sequence = []\n",
    "    for seg in L:\n",
    "        sequence.append(word2idx_outputs.get(seg))\n",
    "    target_input_sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6657 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "max_len_target = max(len(s) for s in target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs.shape: (10000, 9)\n",
      "encoder_inputs[0]: [  0   0   0   0   0   0   0   0 911]\n",
      "decoder_inputs[0]: [3 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "decoder_inputs.shape: (10000, 13)\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(target_input_sequences, maxlen=max_len_target, padding='post')\n",
    "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# store all the pre-trained word vectors\n",
    "word2vec = {}\n",
    "with open(os.path.join('../large_files/glove.6B/glove.6B.%sd.txt' % EMBEDDING_DIM), encoding='utf-8') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "    \n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "  if i < MAX_NUM_WORDS:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=max_len_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, since we cannot use sparse\n",
    "# categorical cross entropy when we have sequences\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(input_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")\n",
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decoder_targets):\n",
    "  for t, word in enumerate(d):\n",
    "    decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### build the model #####\n",
    "\n",
    "# Set up the encoder - simple!\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = Bidirectional(LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_sequences=True,\n",
    "  # dropout=0.5 # dropout not available on gpu\n",
    "))\n",
    "encoder_outputs = encoder(x)\n",
    "\n",
    "\n",
    "# Set up the decoder - not so simple\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "# this word embedding will not use pre-trained vectors\n",
    "# although you could\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Attention #########\n",
    "# Attention layers need to be global because\n",
    "# they will be repeated Ty times at the decoder\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]\n",
    "# make sure we do softmax over the time axis\n",
    "# expected shape is N x T x D\n",
    "# note: the latest version of Keras allows you to pass in axis arg\n",
    "def softmax_over_time(x):\n",
    "  assert(K.ndim(x) > 2)\n",
    "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "  s = K.sum(e, axis=1, keepdims=True)\n",
    "  return e / s\n",
    "\n",
    "def one_step_attention(h, st_1):\n",
    "  # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "  # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
    " \n",
    "  # copy s(t-1) Tx times\n",
    "  # now shape = (Tx, LATENT_DIM_DECODER)\n",
    "  st_1 = attn_repeat_layer(st_1)\n",
    "\n",
    "  # Concatenate all h(t)'s with s(t-1)\n",
    "  # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "  x = attn_concat_layer([h, st_1])\n",
    "\n",
    "  # Neural net first layer\n",
    "  x = attn_dense1(x)\n",
    "\n",
    "  # Neural net second layer with special softmax over time\n",
    "  alphas = attn_dense2(x)\n",
    "\n",
    "  # \"Dot\" the alphas and the h's\n",
    "  # Remember a.dot(b) = sum over a[t] * b[t]\n",
    "  context = attn_dot([alphas, h])\n",
    "\n",
    "  return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the rest of the decoder (after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "\n",
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike previous seq2seq, we cannot get the output\n",
    "# all in one step\n",
    "# Instead we need to do Ty steps\n",
    "# And in each of those steps, we need to consider\n",
    "# all Tx h's\n",
    "\n",
    "# s, c will be re-assigned in each iteration of the loop\n",
    "s = initial_s\n",
    "c = initial_c\n",
    "\n",
    "# collect outputs in a list at first\n",
    "outputs = []\n",
    "for t in range(max_len_target): # Ty times\n",
    "  # get the context using attention\n",
    "  context = one_step_attention(encoder_outputs, s)\n",
    "\n",
    "  # we need a different layer for each time step\n",
    "  selector = Lambda(lambda x: x[:, t:t+1])\n",
    "  xt = selector(decoder_inputs_x)\n",
    "  \n",
    "  # combine \n",
    "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "\n",
    "  # pass the combined [context, last word] into the LSTM\n",
    "  # along with [s, c]\n",
    "  # get the new [s, c] and output\n",
    "  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "\n",
    "  # final dense layer to get next word prediction\n",
    "  decoder_outputs = decoder_dense(o)\n",
    "  outputs.append(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'outputs' is now a list of length Ty\n",
    "# each element is of shape (batch size, output vocab size)\n",
    "# therefore if we simply stack all the outputs into 1 tensor\n",
    "# it would be of shape T x N x D\n",
    "# we would like it to be of shape N x T x D\n",
    "\n",
    "def stack_and_transpose(x):\n",
    "  # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
    "  x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
    "  x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
    "  return x\n",
    "\n",
    "# make it a layer\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)\n",
    "\n",
    "# create the model\n",
    "model = Model(\n",
    "  inputs=[\n",
    "    encoder_inputs_placeholder,\n",
    "    decoder_inputs_placeholder,\n",
    "    initial_s, \n",
    "    initial_c,\n",
    "  ],\n",
    "  outputs=outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 100s 12ms/step - loss: 3.1730 - acc: 0.0144 - val_loss: 3.2157 - val_acc: 0.0614\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 88s 11ms/step - loss: 2.3285 - acc: 0.2061 - val_loss: 3.0750 - val_acc: 0.1947\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 95s 12ms/step - loss: 2.2091 - acc: 0.2425 - val_loss: 3.0271 - val_acc: 0.1968\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 93s 12ms/step - loss: 2.1412 - acc: 0.2442 - val_loss: 2.9942 - val_acc: 0.2007\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 94s 12ms/step - loss: 2.0944 - acc: 0.2480 - val_loss: 2.9690 - val_acc: 0.2028\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 95s 12ms/step - loss: 2.0459 - acc: 0.2575 - val_loss: 2.9194 - val_acc: 0.2089\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 95s 12ms/step - loss: 1.9938 - acc: 0.2637 - val_loss: 2.8848 - val_acc: 0.2118\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 95s 12ms/step - loss: 1.9397 - acc: 0.2730 - val_loss: 2.8758 - val_acc: 0.2231\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 95s 12ms/step - loss: 1.8794 - acc: 0.2918 - val_loss: 2.8397 - val_acc: 0.2383\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 106s 13ms/step - loss: 1.8190 - acc: 0.3172 - val_loss: 2.7926 - val_acc: 0.2543\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 96s 12ms/step - loss: 1.7619 - acc: 0.3323 - val_loss: 2.8031 - val_acc: 0.2703\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 83s 10ms/step - loss: 1.7052 - acc: 0.3482 - val_loss: 2.7562 - val_acc: 0.2692\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 83s 10ms/step - loss: 1.6490 - acc: 0.3620 - val_loss: 2.7466 - val_acc: 0.2783\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 84s 10ms/step - loss: 1.5947 - acc: 0.3766 - val_loss: 2.7336 - val_acc: 0.2843\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 86s 11ms/step - loss: 1.5418 - acc: 0.3890 - val_loss: 2.7101 - val_acc: 0.2915\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 86s 11ms/step - loss: 1.4889 - acc: 0.3998 - val_loss: 2.7006 - val_acc: 0.2954\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 83s 10ms/step - loss: 1.4377 - acc: 0.4092 - val_loss: 2.6938 - val_acc: 0.3010\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 84s 10ms/step - loss: 1.3843 - acc: 0.4212 - val_loss: 2.6801 - val_acc: 0.3087\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 83s 10ms/step - loss: 1.3307 - acc: 0.4367 - val_loss: 2.6705 - val_acc: 0.3101\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 82s 10ms/step - loss: 1.2779 - acc: 0.4481 - val_loss: 2.6688 - val_acc: 0.3204\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 1.2274 - acc: 0.4581 - val_loss: 2.6661 - val_acc: 0.3186\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 79s 10ms/step - loss: 1.1764 - acc: 0.4697 - val_loss: 2.6669 - val_acc: 0.3247\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 1.1282 - acc: 0.4793 - val_loss: 2.6641 - val_acc: 0.3274\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 79s 10ms/step - loss: 1.0796 - acc: 0.4916 - val_loss: 2.6599 - val_acc: 0.3265\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 1.0301 - acc: 0.5051 - val_loss: 2.6488 - val_acc: 0.3291\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.9815 - acc: 0.5180 - val_loss: 2.6491 - val_acc: 0.3351\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 79s 10ms/step - loss: 0.9324 - acc: 0.5324 - val_loss: 2.6638 - val_acc: 0.3364\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.8873 - acc: 0.5473 - val_loss: 2.6705 - val_acc: 0.3363\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.8426 - acc: 0.5642 - val_loss: 2.6718 - val_acc: 0.3395\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.7976 - acc: 0.5828 - val_loss: 2.6787 - val_acc: 0.3401\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.7554 - acc: 0.6039 - val_loss: 2.6852 - val_acc: 0.3417\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.7103 - acc: 0.6267 - val_loss: 2.6926 - val_acc: 0.3413\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.6679 - acc: 0.6509 - val_loss: 2.6985 - val_acc: 0.3430\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.6285 - acc: 0.6731 - val_loss: 2.7119 - val_acc: 0.3449\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.5901 - acc: 0.6950 - val_loss: 2.7192 - val_acc: 0.3444\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.5518 - acc: 0.7155 - val_loss: 2.7418 - val_acc: 0.3494\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.5183 - acc: 0.7331 - val_loss: 2.7472 - val_acc: 0.3486\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.4848 - acc: 0.7511 - val_loss: 2.7606 - val_acc: 0.3495\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 79s 10ms/step - loss: 0.4521 - acc: 0.7698 - val_loss: 2.7814 - val_acc: 0.3513\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 79s 10ms/step - loss: 0.4255 - acc: 0.7850 - val_loss: 2.7922 - val_acc: 0.3482\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.3953 - acc: 0.8011 - val_loss: 2.7999 - val_acc: 0.3456\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.3674 - acc: 0.8149 - val_loss: 2.8202 - val_acc: 0.3512\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.3428 - acc: 0.8281 - val_loss: 2.8369 - val_acc: 0.3494\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.3194 - acc: 0.8406 - val_loss: 2.8577 - val_acc: 0.3485\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.2977 - acc: 0.8542 - val_loss: 2.8722 - val_acc: 0.3498\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.2776 - acc: 0.8636 - val_loss: 2.8874 - val_acc: 0.3451\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.2584 - acc: 0.8748 - val_loss: 2.9080 - val_acc: 0.3481\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.2393 - acc: 0.8858 - val_loss: 2.9229 - val_acc: 0.3484\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.2229 - acc: 0.8931 - val_loss: 2.9377 - val_acc: 0.3456\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.2075 - acc: 0.9025 - val_loss: 2.9613 - val_acc: 0.3471\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 79s 10ms/step - loss: 0.1917 - acc: 0.9130 - val_loss: 2.9861 - val_acc: 0.3484\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 79s 10ms/step - loss: 0.1770 - acc: 0.9209 - val_loss: 3.0011 - val_acc: 0.3479\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.1635 - acc: 0.9280 - val_loss: 3.0219 - val_acc: 0.3461\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.1516 - acc: 0.9338 - val_loss: 3.0262 - val_acc: 0.3466\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 79s 10ms/step - loss: 0.1413 - acc: 0.9394 - val_loss: 3.0621 - val_acc: 0.3470\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.1304 - acc: 0.9455 - val_loss: 3.0728 - val_acc: 0.3469\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 79s 10ms/step - loss: 0.1212 - acc: 0.9505 - val_loss: 3.0932 - val_acc: 0.3466\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.1110 - acc: 0.9553 - val_loss: 3.1169 - val_acc: 0.3480\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.1049 - acc: 0.9585 - val_loss: 3.1301 - val_acc: 0.3493\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.1001 - acc: 0.9612 - val_loss: 3.1407 - val_acc: 0.3455\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0912 - acc: 0.9649 - val_loss: 3.1618 - val_acc: 0.3431\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0822 - acc: 0.9702 - val_loss: 3.1797 - val_acc: 0.3457\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0740 - acc: 0.9733 - val_loss: 3.2051 - val_acc: 0.3454\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 79s 10ms/step - loss: 0.0680 - acc: 0.9757 - val_loss: 3.2311 - val_acc: 0.3467\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0635 - acc: 0.9766 - val_loss: 3.2481 - val_acc: 0.3448\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0619 - acc: 0.9779 - val_loss: 3.2404 - val_acc: 0.3432\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 77s 10ms/step - loss: 0.0557 - acc: 0.9799 - val_loss: 3.2643 - val_acc: 0.3432\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0500 - acc: 0.9817 - val_loss: 3.2867 - val_acc: 0.3461\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0454 - acc: 0.9829 - val_loss: 3.2995 - val_acc: 0.3448\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0428 - acc: 0.9839 - val_loss: 3.3238 - val_acc: 0.3447\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0423 - acc: 0.9837 - val_loss: 3.3440 - val_acc: 0.3451\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0401 - acc: 0.9841 - val_loss: 3.3583 - val_acc: 0.3447\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0376 - acc: 0.9845 - val_loss: 3.3634 - val_acc: 0.3450\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0364 - acc: 0.9846 - val_loss: 3.3718 - val_acc: 0.3452\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0353 - acc: 0.9843 - val_loss: 3.4007 - val_acc: 0.3512\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 79s 10ms/step - loss: 0.0307 - acc: 0.9857 - val_loss: 3.4110 - val_acc: 0.3475\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0268 - acc: 0.9868 - val_loss: 3.4231 - val_acc: 0.3463\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0253 - acc: 0.9860 - val_loss: 3.4410 - val_acc: 0.3468\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0236 - acc: 0.9868 - val_loss: 3.4579 - val_acc: 0.3473\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0232 - acc: 0.9871 - val_loss: 3.4567 - val_acc: 0.3453\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0233 - acc: 0.9861 - val_loss: 3.4855 - val_acc: 0.3475\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0221 - acc: 0.9872 - val_loss: 3.4929 - val_acc: 0.3470\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0303 - acc: 0.9841 - val_loss: 3.4989 - val_acc: 0.3407\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0486 - acc: 0.9745 - val_loss: 3.4915 - val_acc: 0.3421\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 78s 10ms/step - loss: 0.0421 - acc: 0.9782 - val_loss: 3.5047 - val_acc: 0.3474\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 81s 10ms/step - loss: 0.0268 - acc: 0.9846 - val_loss: 3.5025 - val_acc: 0.3469\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 0.0202 - acc: 0.9867 - val_loss: 3.5221 - val_acc: 0.3511\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 87s 11ms/step - loss: 0.0177 - acc: 0.9877 - val_loss: 3.5334 - val_acc: 0.3522\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 99s 12ms/step - loss: 0.0164 - acc: 0.9874 - val_loss: 3.5401 - val_acc: 0.3487\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 90s 11ms/step - loss: 0.0151 - acc: 0.9883 - val_loss: 3.5528 - val_acc: 0.3487\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 0.0146 - acc: 0.9873 - val_loss: 3.5781 - val_acc: 0.3495\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 87s 11ms/step - loss: 0.0142 - acc: 0.9873 - val_loss: 3.5821 - val_acc: 0.3502\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 0.0137 - acc: 0.9880 - val_loss: 3.5889 - val_acc: 0.3493\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 90s 11ms/step - loss: 0.0135 - acc: 0.9872 - val_loss: 3.6106 - val_acc: 0.3484\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 100s 13ms/step - loss: 0.0130 - acc: 0.9875 - val_loss: 3.6261 - val_acc: 0.3506\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 87s 11ms/step - loss: 0.0127 - acc: 0.9878 - val_loss: 3.6384 - val_acc: 0.3505\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 86s 11ms/step - loss: 0.0126 - acc: 0.9877 - val_loss: 3.6443 - val_acc: 0.3495\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 91s 11ms/step - loss: 0.0124 - acc: 0.9877 - val_loss: 3.6581 - val_acc: 0.3517\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 85s 11ms/step - loss: 0.0122 - acc: 0.9875 - val_loss: 3.6529 - val_acc: 0.3501\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 85s 11ms/step - loss: 0.0121 - acc: 0.9880 - val_loss: 3.6572 - val_acc: 0.3486\n"
     ]
    }
   ],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  mask = K.cast(y_true > 0, dtype='float32')\n",
    "  out = mask * y_true * K.log(y_pred)\n",
    "  return -K.sum(out) / K.sum(mask)\n",
    "\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  targ = K.argmax(y_true, axis=-1)\n",
    "  pred = K.argmax(y_pred, axis=-1)\n",
    "  correct = K.cast(K.equal(targ, pred), dtype='float32')\n",
    "\n",
    "  # 0 is padding, don't include those\n",
    "  mask = K.cast(K.greater(targ, 0), dtype='float32')\n",
    "  n_correct = K.sum(mask * correct)\n",
    "  n_total = K.sum(mask)\n",
    "  return n_correct / n_total\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss=custom_loss, metrics=[acc])\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# train the model\n",
    "z = np.zeros((len(encoder_inputs), LATENT_DIM_DECODER)) # initial [s, c]\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='acc')\n",
    "plt.plot(r.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Make predictions #####\n",
    "# As with the poetry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "# i.e. h(1), ..., h(Tx)\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
    "\n",
    "# next we define a T=1 decoder model\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# no need to loop over attention steps this time because there is only one step\n",
    "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
    "\n",
    "# combine context with last word\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm and final dense\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: we don't really need the final stack and tranpose\n",
    "# because there's only 1 output\n",
    "# it is already of size N x D\n",
    "# no need to make it 1 x N x D --> N x 1 x D\n",
    "\n",
    "# create the model object\n",
    "decoder_model = Model(\n",
    "  inputs=[\n",
    "    decoder_inputs_single,\n",
    "    encoder_outputs_as_input,\n",
    "    initial_s, \n",
    "    initial_c\n",
    "  ],\n",
    "  outputs=[decoder_outputs, s, c]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  enc_out = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "  \n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "\n",
    "\n",
    "  # [s, c] will be updated in each loop iteration\n",
    "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "\n",
    "\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  for _ in range(max_len_target):\n",
    "    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
    "        \n",
    "\n",
    "    # Get next word\n",
    "    idx = np.argmax(o.flatten())\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "  return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: When will they arrive?\n",
      "Predicted translation:    ?\n",
      "Actual translation: ?\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: He put the book on the shelf.\n",
      "Predicted translation:    \n",
      "Actual translation: \n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: Let's leave.\n",
      "Predicted translation:  \n",
      "Actual translation: \n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: Choose the one you like.\n",
      "Predicted translation:   \n",
      "Actual translation: \n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: I can't believe he did that.\n",
      "Predicted translation:        \n",
      "Actual translation: \n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: Man cannot live forever.\n",
      "Predicted translation:   \n",
      "Actual translation: \n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: He gave a nice present to me.\n",
      "Predicted translation:       \n",
      "Actual translation: \n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: Don't walk alone after dark.\n",
      "Predicted translation:     \n",
      "Actual translation: \n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: Don't forget us.\n",
      "Predicted translation:  \n",
      "Actual translation: \n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  # Do some test translations\n",
    "  i = np.random.choice(len(input_texts))\n",
    "  input_seq = encoder_inputs[i:i+1]\n",
    "  translation = decode_sequence(input_seq)\n",
    "  print('-')\n",
    "  print('Input sentence:', input_texts[i])\n",
    "  print('Predicted translation:', translation)\n",
    "  print('Actual translation:', target_texts[i])\n",
    "\n",
    "  ans = input(\"Continue? [Y/n]\")\n",
    "  if ans and ans.lower().startswith('n'):\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
