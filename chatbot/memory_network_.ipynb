{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, Lambda, Reshape, add, dot, Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenges = {\n",
    "  # QA1 with 10,000 samples\n",
    "  'single_supporting_fact_10k': '../large_files/tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt',\n",
    "  # QA2 with 10,000 samples\n",
    "  'two_supporting_facts_10k': '../large_files/tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "\n",
    "  >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "  ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "  '''\n",
    "    return [x.strip() for x in re.split('(\\W+?)', sent) if x.strip()]\n",
    "\n",
    "\n",
    "def get_stories(f):\n",
    "    # data will return a list of triples\n",
    "    # each triple contains:\n",
    "    #   1. a story\n",
    "    #   2. a question about the story\n",
    "    #   3. the answer to the question\n",
    "    data = []\n",
    "\n",
    "    # use this list to keep track of the story so far\n",
    "    story = []\n",
    "\n",
    "    # print a random story, helpful to see the data\n",
    "#     printed = False\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "\n",
    "        # split the line number from the rest of the line\n",
    "        nid, line = line.split(' ', 1)\n",
    "\n",
    "        # see if we should begin a new story\n",
    "        if int(nid) == 1:\n",
    "            story = []\n",
    "            # this line contains a question and answer if it has a tab\n",
    "        #       question<TAB>answer\n",
    "        # it also tells us which line in the story is relevant to the answer\n",
    "        # Note: we actually ignore this fact, since the model will learn\n",
    "        #       which lines are important\n",
    "        # Note: the max line number is not the number of lines of the story\n",
    "        #       since lines with questions do not contain any story\n",
    "        # one story may contain MULTIPLE questions\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "\n",
    "            # numbering each line is very useful\n",
    "            # it's the equivalent of adding a unique token to the front\n",
    "            # of each sentence\n",
    "#             story_so_far = [[str(i)] + s for i, s in enumerate(story) if s]\n",
    "            story_so_far = [s for s in story if s]\n",
    "\n",
    "            # uncomment if you want to see what a story looks like\n",
    "            # if not printed and np.random.rand() < 0.5:\n",
    "            #     print(\"story_so_far:\", story_so_far)\n",
    "            #     printed = True\n",
    "            data.append((story_so_far, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            # just add the line to the current story\n",
    "            story.append(tokenize(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "# recursively flatten a list\n",
    "def should_flatten(el):\n",
    "    return not isinstance(el, (str, bytes))\n",
    "\n",
    "\n",
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if should_flatten(el):\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            yield el\n",
    "\n",
    "\n",
    "# convert stories from words into lists of word indexes (integers)\n",
    "# pad each sequence so that they are the same length\n",
    "# we will need to re-pad the stories later so that each story\n",
    "# is the same length\n",
    "def vectorize_stories(data, word2idx, story_maxlen, query_maxlen):\n",
    "    inputs, queries, answers = [], [], []\n",
    "    for story, query, answer in data:\n",
    "        inputs.append([[word2idx[w] for w in s] for s in story])\n",
    "        queries.append([word2idx[w] for w in query])\n",
    "        answers.append([word2idx[answer]])\n",
    "    return ([pad_sequences(x, maxlen=story_maxlen) for x in inputs],\n",
    "            pad_sequences(queries, maxlen=query_maxlen), np.array(answers))\n",
    "\n",
    "\n",
    "# this is like 'pad_sequences' but for entire stories\n",
    "# we are padding each story with zeros so every story\n",
    "# has the same number of sentences\n",
    "# append an array of zeros of size:\n",
    "# (max_sentences - num sentences in story, max words in sentence)\n",
    "def stack_inputs(inputs, story_maxsents, story_maxlen):\n",
    "    for i, story in enumerate(inputs):\n",
    "        inputs[i] = np.concatenate([\n",
    "            story,\n",
    "            np.zeros((story_maxsents - story.shape[0], story_maxlen), 'int')\n",
    "        ])\n",
    "    return np.stack(inputs)\n",
    "\n",
    "\n",
    "# make a function to get the data since\n",
    "# we want to load both the single supporting fact data\n",
    "# and the two supporting fact data later\n",
    "def get_data(challenge_type):\n",
    "    # input should either be 'single_supporting_fact_10k' or 'two_supporting_facts_10k'\n",
    "    challenge = challenges[challenge_type]\n",
    "\n",
    "    # returns a list of triples of:\n",
    "    # (story, question, answer)\n",
    "    # story is a list of sentences\n",
    "    # question is a sentence\n",
    "    # answer is a word\n",
    "    train_file = open(challenge.format('train'), 'r').readlines()\n",
    "    test_file = open(challenge.format('test'), 'r').readlines()\n",
    "    \n",
    "    train_stories = get_stories(train_file)\n",
    "    test_stories = get_stories(test_file)\n",
    "\n",
    "    # group all the stories together\n",
    "    stories = train_stories + test_stories\n",
    "\n",
    "    # so we can get the max length of each story, of each sentence, and of each question\n",
    "    story_maxlen = max((len(s) for x, _, _ in stories for s in x))\n",
    "    story_maxsents = max((len(x) for x, _, _ in stories))\n",
    "    query_maxlen = max(len(x) for _, x, _ in stories)\n",
    "\n",
    "    # Create vocabulary of corpus and find size, including a padding element.\n",
    "    vocab = sorted(set(flatten(stories)))\n",
    "    vocab.insert(0, '<PAD>')\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "    # Create an index mapping for the vocabulary.\n",
    "    word2idx = {c: i for i, c in enumerate(vocab)}\n",
    "\n",
    "    # convert stories from strings to lists of integers\n",
    "    inputs_train, queries_train, answers_train = vectorize_stories(\n",
    "        train_stories, word2idx, story_maxlen, query_maxlen)\n",
    "    inputs_test, queries_test, answers_test = vectorize_stories(\n",
    "        test_stories, word2idx, story_maxlen, query_maxlen)\n",
    "\n",
    "    # convert inputs into 3-D numpy arrays\n",
    "    inputs_train = stack_inputs(inputs_train, story_maxsents, story_maxlen)\n",
    "    inputs_test = stack_inputs(inputs_test, story_maxsents, story_maxlen)\n",
    "    print(\"inputs_train.shape, inputs_test.shape\", inputs_train.shape,\n",
    "          inputs_test.shape)\n",
    "\n",
    "    # return model inputs for keras\n",
    "    return train_stories, test_stories, \\\n",
    "      inputs_train, queries_train, answers_train, \\\n",
    "      inputs_test, queries_test, answers_test, \\\n",
    "      story_maxsents, story_maxlen, query_maxlen, \\\n",
    "      vocab, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_train.shape, inputs_test.shape (10000, 10, 7) (1000, 10, 7)\n"
     ]
    }
   ],
   "source": [
    "# get the single supporting fact data\n",
    "train_stories, test_stories, \\\n",
    "  inputs_train, queries_train, answers_train, \\\n",
    "  inputs_test, queries_test, answers_test, \\\n",
    "  story_maxsents, story_maxlen, query_maxlen, \\\n",
    "  vocab, vocab_size = get_data('single_supporting_fact_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  5 16 19 18  9  1]\n",
      "  [ 0  4 21 19 18 12  1]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]]\n",
      "\n",
      " [[ 0  5 16 19 18  9  1]\n",
      "  [ 0  4 21 19 18 12  1]\n",
      "  [ 3 21  8 19 18 12  1]\n",
      "  [ 0  6 16 19 18 11  1]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]]\n",
      "\n",
      " [[ 0  5 16 19 18  9  1]\n",
      "  [ 0  4 21 19 18 12  1]\n",
      "  [ 3 21  8 19 18 12  1]\n",
      "  [ 0  6 16 19 18 11  1]\n",
      "  [ 0  4 16 19 18 17  1]\n",
      "  [ 0  6 14 19 18  9  1]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([['Mary', 'moved', 'to', 'the', 'bathroom', '.'],\n",
       "   ['John', 'went', 'to', 'the', 'hallway', '.']],\n",
       "  ['Where', 'is', 'Mary', '?'],\n",
       "  'bathroom'),\n",
       " ([['Mary', 'moved', 'to', 'the', 'bathroom', '.'],\n",
       "   ['John', 'went', 'to', 'the', 'hallway', '.'],\n",
       "   ['Daniel', 'went', 'back', 'to', 'the', 'hallway', '.'],\n",
       "   ['Sandra', 'moved', 'to', 'the', 'garden', '.']],\n",
       "  ['Where', 'is', 'Daniel', '?'],\n",
       "  'hallway'),\n",
       " ([['Mary', 'moved', 'to', 'the', 'bathroom', '.'],\n",
       "   ['John', 'went', 'to', 'the', 'hallway', '.'],\n",
       "   ['Daniel', 'went', 'back', 'to', 'the', 'hallway', '.'],\n",
       "   ['Sandra', 'moved', 'to', 'the', 'garden', '.'],\n",
       "   ['John', 'moved', 'to', 'the', 'office', '.'],\n",
       "   ['Sandra', 'journeyed', 'to', 'the', 'bathroom', '.']],\n",
       "  ['Where', 'is', 'Daniel', '?'],\n",
       "  'hallway')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for line in train_stories[0:3]:\n",
    "#     print(line)\n",
    "print(inputs_train[0:3])\n",
    "train_stories[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 7\n"
     ]
    }
   ],
   "source": [
    "print(story_maxsents,story_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 100, 10)\n",
      "(?, 100, 10, 15)\n",
      "(?, 100, 15)\n"
     ]
    }
   ],
   "source": [
    "# # test for dimension\n",
    "# story_maxsents = 100\n",
    "# story_maxlen = 10\n",
    "# vocab_size = 3000\n",
    "# embedding_dim = 15\n",
    "\n",
    "\n",
    "# input_1 = Input((story_maxsents, story_maxlen))\n",
    "\n",
    "# embedded_1 = Embedding(vocab_size, embedding_dim)(input_1)\n",
    "# embedded_2 = Lambda(lambda x: K.sum(x, axis=2))(embedded_1)\n",
    "\n",
    "# print(input_1.shape)\n",
    "# print(embedded_1.shape)\n",
    "print(embedded_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_story_.shape, embedded_story.shape: (?, 10, 7) (?, 10, 15)\n",
      "inp_q.shape, emb_q.shape: (?, 4) (?, 1, 15)\n",
      "story_weights.shape: (?, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "##### create the model #####\n",
    "embedding_dim = 15\n",
    "\n",
    "\n",
    "# turn the story into a sequence of embedding vectors\n",
    "# one for each story line\n",
    "# treating each story line like a \"bag of words\"\n",
    "input_story_ = Input((story_maxsents, story_maxlen))\n",
    "embedded_story = Embedding(vocab_size, embedding_dim)(input_story_)\n",
    "embedded_story = Lambda(lambda x: K.sum(x, axis=2))(embedded_story)\n",
    "print(\"input_story_.shape, embedded_story.shape:\", input_story_.shape, embedded_story.shape)\n",
    "\n",
    "\n",
    "# turn the question into an embedding\n",
    "# also a bag of words\n",
    "input_question_ = Input((query_maxlen,))\n",
    "embedded_question = Embedding(vocab_size, embedding_dim)(input_question_)\n",
    "embedded_question = Lambda(lambda x: K.sum(x, axis=1))(embedded_question)\n",
    "\n",
    "# add a \"sequence length\" of 1 so that it can\n",
    "# be dotted with the story later\n",
    "embedded_question = Reshape((1, embedding_dim))(embedded_question)\n",
    "print(\"inp_q.shape, emb_q.shape:\", input_question_.shape, embedded_question.shape)\n",
    "\n",
    "\n",
    "# calculate the weights for each story line\n",
    "# embedded_story.shape        = (N, num sentences, embedding_dim)\n",
    "# embedded_question.shape     = (N, 1, embedding_dim)\n",
    "x = dot([embedded_story, embedded_question], 2)\n",
    "x = Reshape((story_maxsents,))(x) # flatten the vector\n",
    "x = Activation('softmax')(x)\n",
    "story_weights = Reshape((story_maxsents, 1))(x) # unflatten it again to be dotted later\n",
    "print(\"story_weights.shape:\", story_weights.shape)\n",
    "\n",
    "\n",
    "\n",
    "x = dot([story_weights, embedded_story], 1)\n",
    "x = Reshape((embedding_dim,))(x) # flatten it again\n",
    "ans = Dense(vocab_size, activation='softmax')(x)\n",
    "\n",
    "# make the model\n",
    "model = Model([input_story_, input_question_], ans)\n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "  optimizer=RMSprop(lr=1e-2),\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/4\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 1.1408 - accuracy: 0.5318 - val_loss: 0.8661 - val_accuracy: 0.6320\n",
      "Epoch 2/4\n",
      "10000/10000 [==============================] - 1s 60us/step - loss: 0.7469 - accuracy: 0.6426 - val_loss: 0.7958 - val_accuracy: 0.6310\n",
      "Epoch 3/4\n",
      "10000/10000 [==============================] - 1s 60us/step - loss: 0.7318 - accuracy: 0.6475 - val_loss: 0.7433 - val_accuracy: 0.6500\n",
      "Epoch 4/4\n",
      "10000/10000 [==============================] - 1s 59us/step - loss: 0.7289 - accuracy: 0.6451 - val_loss: 0.7301 - val_accuracy: 0.6440\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "r = model.fit(\n",
    "  [inputs_train, queries_train],\n",
    "  answers_train,\n",
    "  epochs=4,\n",
    "  batch_size=32,\n",
    "  validation_data=([inputs_test, queries_test], answers_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story:\n",
      "\n",
      "0.01082 \t Sandra went to the bedroom .\n",
      "0.00643 \t Sandra moved to the kitchen .\n",
      "0.37231 \t John moved to the hallway .\n",
      "0.24009 \t John journeyed to the garden .\n",
      "0.00257 \t Mary went back to the office .\n",
      "0.35832 \t John went to the office .\n",
      "question: Where is John ?\n",
      "answer: office\n"
     ]
    }
   ],
   "source": [
    "# Check how we weight each input sentence given a story and question\n",
    "debug_model = Model([input_story_, input_question_], story_weights)\n",
    "\n",
    "# choose a random story\n",
    "story_idx = np.random.choice(len(train_stories))\n",
    "\n",
    "# get weights from debug model\n",
    "i = inputs_train[story_idx:story_idx+1]\n",
    "q = queries_train[story_idx:story_idx+1]\n",
    "w = debug_model.predict([i, q]).flatten()\n",
    "\n",
    "story, question, ans = train_stories[story_idx]\n",
    "print(\"story:\\n\")\n",
    "for i, line in enumerate(story):\n",
    "  print(\"{:1.5f}\".format(w[i]), \"\\t\", \" \".join(line))\n",
    "\n",
    "print(\"question:\", \" \".join(question))\n",
    "print(\"answer:\", ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story:\n",
      "John journeyed to the garden .\n",
      "Sandra moved to the bedroom .\n",
      "John journeyed to the office .\n",
      "John went back to the garden .\n",
      "question: Where is John ?\n",
      "answer: garden\n",
      "Countinue?[y/n] \n",
      "y\n",
      "story:\n",
      "Mary travelled to the hallway .\n",
      "Sandra went to the garden .\n",
      "Daniel travelled to the bedroom .\n",
      "Mary went to the bedroom .\n",
      "question: Where is Daniel ?\n",
      "answer: bedroom\n",
      "Countinue?[y/n] \n",
      "y\n",
      "story:\n",
      "John went to the garden .\n",
      "Daniel went to the hallway .\n",
      "John moved to the bathroom .\n",
      "John went to the kitchen .\n",
      "John moved to the garden .\n",
      "John travelled to the kitchen .\n",
      "Daniel travelled to the bathroom .\n",
      "Sandra went to the office .\n",
      "question: Where is Daniel ?\n",
      "answer: bathroom\n",
      "Countinue?[y/n] \n",
      "y\n",
      "story:\n",
      "Daniel went back to the bedroom .\n",
      "John went back to the hallway .\n",
      "Sandra journeyed to the garden .\n",
      "Daniel journeyed to the garden .\n",
      "Sandra journeyed to the bathroom .\n",
      "John travelled to the bedroom .\n",
      "Sandra went to the kitchen .\n",
      "John journeyed to the bathroom .\n",
      "question: Where is Sandra ?\n",
      "answer: kitchen\n",
      "Countinue?[y/n] \n",
      "y\n",
      "story:\n",
      "Mary travelled to the garden .\n",
      "Daniel went to the garden .\n",
      "John journeyed to the garden .\n",
      "Mary journeyed to the office .\n",
      "Daniel travelled to the bathroom .\n",
      "Daniel travelled to the office .\n",
      "question: Where is John ?\n",
      "answer: garden\n",
      "Countinue?[y/n] \n",
      "y\n",
      "story:\n",
      "Daniel travelled to the office .\n",
      "John went to the bathroom .\n",
      "question: Where is John ?\n",
      "answer: bathroom\n",
      "Countinue?[y/n] \n",
      "n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    story_idx = np.random.choice(len(train_stories))\n",
    "\n",
    "    # get weights from debug model\n",
    "    i = inputs_train[story_idx:story_idx+1]\n",
    "    q = queries_train[story_idx:story_idx+1]\n",
    "    w = debug_model.predict([i, q]).flatten()\n",
    "\n",
    "    story, question, ans = train_stories[story_idx]\n",
    "    print(\"story:\")\n",
    "    for line in (story):\n",
    "        print(\" \".join(line))\n",
    "\n",
    "    print(\"question:\", \" \".join(question))\n",
    "    print(\"answer:\", ans)\n",
    "    \n",
    "    response = input(\"Countinue?[y/n] \\n\")\n",
    "    if  response.lower().startswith('n'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
